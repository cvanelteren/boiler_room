#+title: The effect of three point interaction in the stability of criminal organizations
#+latex_class: fun_article
#+author: Casper van Elteren,
#+author: Vitor Vasconcelos,
#+author: Mike Lees

* Background
- Criminal organizations form dangers to society and rule of law
- Most criminal studies are performed in an observational capacity
- Theories  are formed  based  on biased  data with  limited
  validation capacity
- There is a lot of  opportunity to use computational models
  to study the consequences of theories in criminal science

* Aim of the study
Produce a computational model rooted in game theory to study
the  emergent  properties  of   success  supply  chain  of
criminal markets in society.

The  goal  is to  come  up  with  a  model of  supply  chain
interactions in  criminal markets and slowly  introduce more
complexities.  Initially,  we  focus the  attention  on  the
interaction of  a criminal supply chain  without competition
in  a  well-mixed  population.  Later, we  can  add  network
effects and effects of rivalry.

Law enforcement is  embedded as an apprehension  cost and can
be represented as heath bath of the system.


* The model
Let $\sigma_i^X \in \{ 0, 1  \} = \{\textrm{do not perform criminal
act}, \textrm{perform criminal act}  \}$ denote the state of
agent $i$ with roles  category $X \in \{ \textrm{Production)},
\textrm{D(istribution)},              \textrm{M(anagement)},
\textrm{C(ivilian)}\}$.  Each agent  has has  a connectivity
structure  according  to  adjacency   matrix  $A$  where  an
non-zero  entry $a_{ij}$  indicates the  connection strength
$a_{ij}  \in \mathbb{R}$  between agent  $i$  and agent  $j$. We  first
consider symmetrical adjacency  matrices and fully connected
graphs without self-connections and  each edge weight having
value  1.  The  roles  of   each  agent  are  assigned  with
probability $p(x  \in X)  = \frac{1}  {| X  |}$, agent  do not
change their role within each  simulation run. The agent can
decide to participate or not in  a criminal act based on the
state of the local connections.

* The pay-off matrix
We  are  interested  in  studying  the  interaction  between
successful criminal supply chains  and citizens. The maximum
pay-off for a criminal organization is to have a functioning
supply chain.  This implies that  there exist a  four point
interaction  between the  roles of  production, distribution
and management; the criminal  organization is most effective
when the product of  interest (drugs, weapons, illegal goods
etc) is readily  available and can be shipped  to and bought
by  customers  (civilians).  A  civilian  can  benefit  from
criminal goods due to a  /need/ of the product, or obtaining
a product at cheaper than market prices.

We   therefore  delineate   the  following   variables.  The
variables are listed as benefits ($b_x$) and costs ($c_x$).
- $b_m$  monetary benefit  of  forming  a complete  criminal
  supply chain (production, distribution, management)
- $b_s$ sales benefit of  forming a complete criminal supply
  chain with customers
- $c_a$ detection cost of committing crime

 #+caption: Supply chain pay-off. Note empty cell indicate no pay-off.
 | Roles      |              |            |          | Pay-off    |              |                   |          |
 | Production | Distribution | Management | Civilian | Production | Distribution | Management        | Civilian |
 |------------+--------------+------------+----------+------------+--------------+-------------------+----------|
 | C          | C            | C          | C        | $b_s -c_a$ | $b_s -c_a$   | $b_s + b_m - c_a$ | $b_m$    |
 | C          | D            | C          | C        | $-c_a$     |              | $-c_a$            |          |
 | C          | C            | D          | C        | $-c_a$     | $-c_a$       |                   |          |
 | C          | C            | C          | D        | $-c_a$     | $-c_a$       | $-c_a$            |          |
 | C          | D            | D          | C        | $-c_a$     |              |                   |          |
 | C          | D            | D          | D        | $-c_a$     |              |                   |          |
 | C          | D            | C          | C        | $-c_a$     |              | $-c_s$            |          |
 | C          | C            | D          | D        | $-c_a$     | $-c_a$       |                   |          |
 | C          | D            | C          | D        |            |              | -$c_a$            |          |
 | D          | C            | C          | C        |            | $-c_a$       | $-c_a$            |          |
 | D          | D            | C          | C        |            |              | $-c_a$            |          |
 | D          | D            | D          | C        |            |              |                   |          |
 | D          | C            | C          | D        |            | $-c_a$       | $-c_a$            |          |
 | D          | C            | D          | C        |            | $-c_a$       |                   |          |
 | D          | D            | D          | D        |            |              |                   |          |
 | D          | D            | C          | D        |            |              | $c_a$             |          |
 | D          | D            | D          | D        |            |              |                   |          |




* Evolutionary Dynamics
We  evaluate the  evolutionary dynamics  by using  the Fermi
update. Let $x$ denote the  flip probability for an agent of
moving from  strategy $i  \to j$  or vice  versa, then  we can
define the Fermi update as
#+name: fermi-update
\begin{equation}
p(x)_{i \to j} = \frac{1}{1 + \exp(-\beta (E_j- E_i))}
\end{equation}

where  $E_i$  is the  pay-off  or  "energy" of  the  current
strategy  of  an  agent  and $E_j$  the  energy  when  using
strategy $j$. The  $\beta$ parameter denotes the  noise. For low
values the flip probability  approaches one. This represents
the conditions  by which the  agent is highly  influenced by
its environment  and will  adopt strategies  accordingly. In
contrast, high  values of $\beta$ represents  scenarios where an
agent is  making a decision  in a highly  noisy environment,
and their strategy  approaches a random choice  to defect or
conform.

* Simulation

#+caption: Creating the data structures
#+begin_src jupyter-python

from dataclasses import dataclass
import pandas as pd

@dataclass
class Payoff:
    benefits: list
    costs: list
@dataclass
class Config:
    payoff: Payoff
    beta: float
    role_map: dict
    roles: dict




#+end_src

#+RESULTS:

#+caption: Update rules
#+begin_src jupyter-python
def fermi_update(agent: int,
                 g: nx.Graph,
                 payoff: dict,
                 roles: dict,
                 role_map: dict,
                 beta = 1.0) -> float:
    # get neighbor from each missing sub population
    neighbors = list(g.neighbors(agent))
    np.random.shuffle(neighbors)
    r = {}
    r[g.nodes[ agent ]["role"]] = g.nodes[agent]["state"]
    for neighbor in neighbors:
        if len(r) == len(roles):
            break
        neighbor = g.nodes[neighbor]
        if neighbor["role"] not in states:
            r[neighbor["role"]] = neighbor["state"]

    current_state = "".join(r[role] for role in roles)
    current = g.nodes[agent]["state"]
    not_current = "C" if current == "D" else "C"
    swapped_state = list(current_state)

    role_idx = role_map[g.nodes[agent]["role"]]
    swapped_state[role_idx] = not_current

    swapped_state = "".join(i for i in swapped_state)

    state_i = payoff[current_state]
    state_j = payoff[swapped_state]
    # lookup payoff for current node

    delta = (state_j.benefits[role_idx] - state_j.costs[role_idx]) - (state_i.benefits[role_idx] - state_i.costs[role_idx])
    p =  1 / (1 + np.exp(- beta * delta))
    if np.random.rand() < p:
        return not_current
    return current

    # collect states and index into the correct
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import networkx as nx, numpy as np
def make_graph(n: int, config: Config) -> nx.Graph:
    node_roles = []
    node_states = []
    for role in roles:
        for idx in range(n // len(roles)):
            node_roles.append(role)
            s = "C"
            if np.random.rand() < 0.5:
                s = "D"
            node_states.append(s)

    g = nx.complete_graph(n)
    R = { node: role for node, role in enumerate(node_roles) }
    S = {node: state for node, state in enumerate(node_states)}
    nx.set_node_attributes(g, R, "role")
    nx.set_node_attributes(g, S, "state")

    return g


def simulate(t, g, config) -> nx.Graph:
    n = len(g)
    states = []
    for ti in range(t):
        agent = np.random.randint(0, n)
        new_strat = fermi_update(agent, g,  payoff = config.payoff, roles = config.roles,
             role_map = config.role_map, beta = config.beta)
        g.nodes[agent]["state"] = new_strat
        states.append(g.copy())
    return states

#+end_src

#+RESULTS:

#+name: setup simulation
#+begin_src jupyter-python
df = pd.read_csv("./test.csv", header = None, skiprows = 2)
roles = "Production Distribution Management Civilian".split()
categories = "Roles Benefits Costs".split()
names = [(j, i) for j in categories for i in roles]
names = pd.MultiIndex.from_tuples(
    names
)
df.columns = names

role_map = { role: idx for idx, role in enumerate(roles) }
payoff = {}
for idx, row in df.Roles.iterrows():
    state = "".join(i for i in [row.Production, row.Distribution, row.Management, row.Civilian])
    payoff[state] = Payoff(benefits=df.Benefits.iloc[idx].values, costs= df.Costs.iloc[idx].values)

config = Config(payoff = payoff,
                role_map = role_map,
                roles = roles,
                beta = 1.0)

g = make_graph(100, config)
g_orig = g.copy()
T = 1000
states = simulate(t = T, g = g, config = config)
pos = nx.random_layout(g)

#+end_src

#+RESULTS: setup simulation

#+name: plotting results
#+begin_src jupyter-python
import proplot as plt

def plot_graph(g, ax):
    for marker, role in zip(markers, roles):
        sublist = [node  for node in g.nodes() if g.nodes[node]["role"] == role]
        C = [colors[0] if g.nodes[node]["state"] == "C" else colors[1] for node in sublist]
        nx.draw_networkx_nodes(g, ax = ax, pos = pos,
                            node_shape = marker,
                            nodelist = sublist,
                            node_size = 12,
                            node_color= C)


    nx.draw_networkx_edges(g, pos, ax = ax, alpha = 0.05)



markers = "os^v"
colors = "darkorange cadetblue orange yellow".split()
fig, (left, right) = plt.subplots(ncols = 2)
plot_graph(states[0], right)
plot_graph(states[-1], left)
left.set_title("T = 0")
right.set_title(f"T = {T}")

fig.format(grid = False)
labels = [plt.pyplot.Line2D([], [], marker = marker,
                      ls = "none", label = label, color = "k") for marker, label in zip(markers, roles)]
state_marker = [plt.pyplot.Line2D([], [], marker = "o",
                      ls = "none", label = label, color = color) for color, label in zip(colors,"C D".split())]
fig.legend(handles = labels, loc = "t")
fig.legend(handles = state_marker, loc = "b")
fig.show()
#+end_src

#+RESULTS: plotting results
:RESULTS:
: /tmp/ipykernel_163944/2299970726.py:33: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.
:   fig.show()
#+attr_org: :width 525 :height 375
[[file:./.ob-jupyter/e19c9e19caa93aeb10329c74f688cd83aa419581.png]]
:END:

#+begin_src jupyter-python
Z = np.zeros((len(states), len(roles)))
for idx, state in enumerate(states):
    for node in state.nodes():
        s = state.nodes[node]["state"]
        role = state.nodes[node]["role"]
        if s == "C":
            Z[idx, role_map[role]] += 1 / len(g)

fig, ax = plt.subplots()
ax.plot(Z)
ax.format(xlabel = "Time(step)", ylabel = "Frac. Conformers (x/Z)")
ax.set_title("Conformers over time (Z = 100)")
fig.show()
#+end_src

#+RESULTS:
